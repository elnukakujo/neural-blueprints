{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77536a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from neural_blueprints.architectures import VariationalAutoEncoder\n",
    "from neural_blueprints.config.architectures import AutoEncoderConfig\n",
    "from neural_blueprints.config.components.composite import EncoderConfig, DecoderConfig\n",
    "from neural_blueprints.config.components.core import DenseLayerConfig\n",
    "from neural_blueprints.config.utils import TrainerConfig\n",
    "from neural_blueprints.config.components.composite.projections.input import TabularInputProjectionConfig\n",
    "from neural_blueprints.config.components.composite.projections.output import TabularOutputProjectionConfig\n",
    "from neural_blueprints.utils import Trainer, infer_types\n",
    "from neural_blueprints.preprocess import TabularPreprocessor\n",
    "from neural_blueprints.datasets import TabularDataset, MaskedTabularDataset, TabularSingleLabelDataset\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # or DEBUG if you want even more detail\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_openml(name=\"adult\", version=2, as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "data = X.copy()\n",
    "data['income'] = y\n",
    "\n",
    "dtypes = infer_types(data)\n",
    "data = data.astype(dtypes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda2f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TabularPreprocessor()\n",
    "data, discrete_features, continuous_features = preprocessor.run(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae78ff",
   "metadata": {},
   "source": [
    "### Income Inference Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TabularSingleLabelDataset(\n",
    "    data=data,\n",
    "    label_column='income',              # Specify the label column for single-label classification\n",
    "    discrete_features=discrete_features,\n",
    "    continuous_features=continuous_features\n",
    ")\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a142c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "\n",
    "vae_config = AutoEncoderConfig(\n",
    "    input_projection=TabularInputProjectionConfig(\n",
    "        cardinalities=dataset.cardinalities,\n",
    "        hidden_dims=[128],\n",
    "        output_dim=[len(dataset.cardinalities)*64],\n",
    "        normalization=\"layernorm\",\n",
    "        activation=\"gelu\",\n",
    "        dropout_p=0.2\n",
    "    ),\n",
    "    output_projection=TabularOutputProjectionConfig(\n",
    "        output_cardinalities=[2],\n",
    "        input_dim=[latent_dim*8],\n",
    "        hidden_dims=[],\n",
    "        normalization=\"layernorm\",\n",
    "        activation=\"gelu\",\n",
    "        dropout_p=0.2\n",
    "    ),\n",
    "    encoder_config=EncoderConfig(\n",
    "        normalization=\"layernorm\",\n",
    "        activation=\"gelu\",\n",
    "        dropout_p=0.2,\n",
    "        layer_configs=[\n",
    "            DenseLayerConfig(input_dim=len(dataset.cardinalities)*64, output_dim=len(dataset.cardinalities)*32),\n",
    "            DenseLayerConfig(input_dim=len(dataset.cardinalities)*32, output_dim=len(dataset.cardinalities)*16),\n",
    "            DenseLayerConfig(input_dim=len(dataset.cardinalities)*16, output_dim=latent_dim*2)\n",
    "        ]\n",
    "    ),\n",
    "    decoder_config=DecoderConfig(\n",
    "        normalization=\"layernorm\",\n",
    "        activation=\"gelu\",\n",
    "        dropout_p=0.2,\n",
    "        layer_configs=[\n",
    "            DenseLayerConfig(input_dim=latent_dim, output_dim=latent_dim*2),\n",
    "            DenseLayerConfig(input_dim=latent_dim*2, output_dim=latent_dim*4),\n",
    "            DenseLayerConfig(input_dim=latent_dim*4, output_dim=latent_dim*8)\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "model = VariationalAutoEncoder(vae_config)\n",
    "model.blueprint(batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    config=TrainerConfig(\n",
    "        learning_rate=1e-3,\n",
    "        weight_decay=1e-5,\n",
    "        batch_size=256,\n",
    "        early_stopping_patience=2,\n",
    "        save_weights_path=\"./models/vae_adult.pth\",\n",
    "        criterion=\"vae_cross_entropy\",\n",
    "        optimizer='adam'\n",
    "    ),\n",
    "    model=model\n",
    ")\n",
    "trainer.train(train_dataset=train_dataset, val_dataset=val_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d28d1e",
   "metadata": {},
   "source": [
    "### Masked Dataset Inference Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50dfb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TabularDataset(\n",
    "    data = data,\n",
    "    discrete_features = discrete_features,\n",
    "    continuous_features = continuous_features\n",
    ")\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "\n",
    "vae_config = AutoEncoderConfig(\n",
    "    input_projection=TabularInputProjectionConfig(\n",
    "        cardinalities=dataset.cardinalities,\n",
    "        hidden_dims=[128],\n",
    "        output_dim=[len(dataset.cardinalities)*64],\n",
    "        normalization=\"layernorm\",\n",
    "        activation=\"gelu\",\n",
    "        dropout_p=0.2\n",
    "    ),\n",
    "    output_projection=TabularOutputProjectionConfig(\n",
    "        output_cardinalities=dataset.cardinalities,\n",
    "        input_dim=[latent_dim*8],\n",
    "        hidden_dims=[],\n",
    "        normalization=\"layernorm\",\n",
    "        activation=\"gelu\",\n",
    "        dropout_p=0.2\n",
    "    ),\n",
    "    encoder_config=EncoderConfig(\n",
    "        normalization=\"layernorm\",\n",
    "        activation=\"gelu\",\n",
    "        dropout_p=0.2,\n",
    "        layer_configs=[\n",
    "            DenseLayerConfig(input_dim=len(dataset.cardinalities)*64, output_dim=len(dataset.cardinalities)*32),\n",
    "            DenseLayerConfig(input_dim=len(dataset.cardinalities)*32, output_dim=len(dataset.cardinalities)*16),\n",
    "            DenseLayerConfig(input_dim=len(dataset.cardinalities)*16, output_dim=latent_dim*2)\n",
    "        ]\n",
    "    ),\n",
    "    decoder_config=DecoderConfig(\n",
    "        normalization=\"layernorm\",\n",
    "        activation=\"gelu\",\n",
    "        dropout_p=0.2,\n",
    "        layer_configs=[\n",
    "            DenseLayerConfig(input_dim=latent_dim, output_dim=latent_dim*2),\n",
    "            DenseLayerConfig(input_dim=latent_dim*2, output_dim=latent_dim*4),\n",
    "            DenseLayerConfig(input_dim=latent_dim*4, output_dim=latent_dim*8)\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "model = VariationalAutoEncoder(vae_config)\n",
    "model.blueprint(batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    config=TrainerConfig(\n",
    "        learning_rate=1e-3,\n",
    "        weight_decay=1e-5,\n",
    "        batch_size=256,\n",
    "        early_stopping_patience=2,\n",
    "        save_weights_path=\"./models/vae_adult.pth\",\n",
    "        criterion=\"vae_reconstruction\",\n",
    "        optimizer='adam'\n",
    "    ),\n",
    "    model=model\n",
    ")\n",
    "trainer.train(train_dataset=train_dataset, val_dataset=val_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fee5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MaskedTabularDataset(\n",
    "    data=data,\n",
    "    discrete_features=discrete_features,\n",
    "    continuous_features=continuous_features,\n",
    "    mask_prob=0.35\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    config=TrainerConfig(\n",
    "        learning_rate=1e-3,\n",
    "        weight_decay=1e-5,\n",
    "        batch_size=128,\n",
    "        early_stopping_patience=2,\n",
    "        save_weights_path=\"./models/vae_adult.pth\",\n",
    "        criterion=\"vae_masked_reconstruction\",\n",
    "        optimizer='adam'\n",
    "    ),\n",
    "    model=model\n",
    ")\n",
    "trainer.predict(test_dataset=test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-blueprints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
